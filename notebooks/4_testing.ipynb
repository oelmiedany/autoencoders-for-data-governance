{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp testing\n",
    "#|export\n",
    "\n",
    "from LendingClubAutoencoder import preprocessing, autoencoders, training\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|test\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def test_error_score(reconstruction:torch.Tensor, x:torch.Tensor, not_null_mask:torch.Tensor, binary_mask:torch.Tensor)->tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    '''\n",
    "    Custom VAE loss function with masking for handling replaced NaN values\n",
    "    \n",
    "    Args:\n",
    "        reconstruction (torch.Tensor): Reconstructed input from the decoder\n",
    "        x (torch.Tensor): Original input\n",
    "        mean (torch.Tensor): Mean of the latent distribution\n",
    "        mask (torch.Tensor): Binary mask where 1 indicates valid values and 0 indicates replaced NaN values\n",
    "\n",
    "    Returns:\n",
    "        tuple: (total_loss, reconstruction_loss, kl_divergence_loss)\n",
    "    '''\n",
    "\n",
    "    # Reconstruction Loss (masked MSE)\n",
    "    inverse_binary_mask = ~binary_mask\n",
    "\n",
    "    binary_mask = not_null_mask & binary_mask[None, :]\n",
    "    numeric_mask = not_null_mask & inverse_binary_mask[None, :]\n",
    "    \n",
    "    mse_loss = F.mse_loss(reconstruction[numeric_mask], x[numeric_mask], reduction='mean')# Only compute MSE for non-masked values\n",
    "    rmse_loss = torch.sqrt(mse_loss)\n",
    "\n",
    "\n",
    "    binary_values = (x[binary_mask] > 0.5).long()\n",
    "    predicted_values = (reconstruction[binary_mask] > 0.5).long()\n",
    "    f1_score = multiclass_f1_score(predicted_values, binary_values, num_classes=2, average='macro')\n",
    "        \n",
    "    return rmse_loss, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def test_vae(model_file_name, test_loader, sigmoid_mask, binary_mask, device):\n",
    "    \n",
    "    model = training.get_best_model(autoencoders.VariationalAutoencoder, sigmoid_mask, model_file_name)\n",
    "    \n",
    "    model.eval()\n",
    "    test_rmse_loss = 0\n",
    "    test_f1_score = 0\n",
    "    n_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data_batch, mask_batch in test_loader:\n",
    "            data_batch, mask_batch = data_batch.to(device), mask_batch.to(device)\n",
    "            reconstruction, mean = model(data_batch)\n",
    "            \n",
    "            rmse_loss, f1_score = test_error_score(reconstruction, data_batch, mask_batch, binary_mask)\n",
    "            \n",
    "            test_rmse_loss = test_rmse_loss + rmse_loss.item()\n",
    "            test_f1_score = test_f1_score + f1_score.item()\n",
    "            n_batches = n_batches + 1\n",
    "\n",
    "    average_rmse_loss = test_rmse_loss / n_batches\n",
    "    average_f1_score = test_f1_score/ n_batches\n",
    "\n",
    "    return average_rmse_loss, average_f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def cross_validate_vae(lending_club_data_handler: preprocessing.DataHandler, start: int, end: int, sigmoid_mask: torch.Tensor, binary_mask: torch.Tensor, learning_rate: float = 1e-3, n_folds: int = 5 ):\n",
    "    '''\n",
    "    Perform k-fold cross-validation for the VAE\n",
    "    \n",
    "    Args:\n",
    "        start (datetime): Start date\n",
    "        end (datetime): End date\n",
    "        n_folds (int): Number of folds\n",
    "    '''\n",
    "\n",
    "    total_days = (end - start).days\n",
    "\n",
    "    train_size = 0.7\n",
    "    validation_size = 0.15\n",
    "    test_size = 0.15\n",
    "\n",
    "    window_size = total_days / (1+train_size*(n_folds-1))\n",
    "    train_step_size = window_size * train_size\n",
    "    validation_step_size = window_size * validation_size\n",
    "    test_step_size = window_size * test_size\n",
    "\n",
    "    fold_test_losses = {}\n",
    "\n",
    "    current_start = start\n",
    "\n",
    "    for fold in range(n_folds):\n",
    "        train_start = current_start\n",
    "        train_end = train_start + timedelta(days=int(train_step_size))\n",
    "\n",
    "        validation_start = train_end + timedelta(days=1)\n",
    "        validation_end = validation_start + timedelta(days=int(validation_step_size))\n",
    "\n",
    "        test_start = validation_end + timedelta(days=1)\n",
    "        test_end = test_start + timedelta(days=int(test_step_size))\n",
    "\n",
    "        current_start = validation_start\n",
    "        \n",
    "        # Ensure we don't go past the end date\n",
    "        if test_end > end:\n",
    "            test_end = end\n",
    "\n",
    "        train_data, train_mask = lending_club_data_handler.get_train_data(train_start, train_end)\n",
    "        validation_data, validation_mask = lending_club_data_handler.get_test_data(validation_start, validation_end)\n",
    "        test_data, test_mask = lending_club_data_handler.get_test_data(test_start, test_end)\n",
    "\n",
    "        train_loader = preprocessing.to_torch_dataloader(train_data,train_mask)\n",
    "        validation_loader = preprocessing.to_torch_dataloader(validation_data,validation_mask)\n",
    "        test_loader = preprocessing.to_torch_dataloader(test_data,test_mask)\n",
    "\n",
    "\n",
    "        # Instantiate model and optimiser \n",
    "        model = autoencoders.VariationalAutoencoder(input_size=len(train_data[0]), sigmoid_mask=sigmoid_mask)\n",
    "        optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)#original is 1e-3\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Train model for this fold \n",
    "        training.train_variational_autoencoder(model, optimiser, train_loader, validation_loader, binary_mask=binary_mask, device=device)\n",
    "\n",
    "        # Evaluate best model for this fold\n",
    "        model_file_name = f'trained_models/vae_best-input_size:{len(train_data[0])}.pt'\n",
    "        \n",
    "        test_rmse_loss, test_f1_score = test_vae(model_file_name, test_loader, device)\n",
    "\n",
    "        fold_test_losses[fold]={'rmse_loss':test_rmse_loss, 'fq_score':test_f1_score}\n",
    "        print(f'Test Loss for Fold {fold+1}: {test_rmse_loss:.4f}, {test_f1_score:.4f}')\n",
    "\n",
    "    return fold_test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|test\n",
    "\n",
    "start = datetime(2007, 1, 1)\n",
    "end = datetime(2017, 5, 31)\n",
    "\n",
    "results = {}\n",
    "results['cv_results'] = cross_validate_vae(start, end)\n",
    "json.dump(results, open('cv_results.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|test\n",
    "\n",
    "lending_club_data_handler = preprocessing.DataHandler(csv_path='../local_data/all_lending_club_loan_data_2007-2018.csv')\n",
    "\n",
    "train_start = datetime(2007, 1, 1)\n",
    "train_end = datetime(2017, 5, 31)\n",
    "\n",
    "validation_start = datetime(2017, 6, 1)\n",
    "validation_end = datetime(2017, 12, 31)\n",
    "\n",
    "\n",
    "train_data, train_mask = lending_club_data_handler.get_train_data(train_start, train_end)\n",
    "validation_data, validation_mask = lending_club_data_handler.get_test_data(validation_start, validation_end)\n",
    "\n",
    "train_loader = preprocessing.to_torch_dataloader(train_data,train_mask)\n",
    "validation_loader = preprocessing.to_torch_dataloader(validation_data,validation_mask)\n",
    "\n",
    "\n",
    "# Instantiate model and optimiser \n",
    "model = autoencoders.VariationalAutoencoder(input_size=len(train_data[0]))\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)#original is 1e-3\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Train model for this fold \n",
    "training.train_variational_autoencoder(model, optimiser, train_loader, validation_loader, device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|test\n",
    "\n",
    "# Evaluate best model for this fold\n",
    "test_start = datetime(2018, 1, 1)\n",
    "test_end = datetime(2018, 12, 31)\n",
    "\n",
    "test_data, test_mask = lending_club_data_handler.get_test_data(test_start, test_end)\n",
    "test_loader = preprocessing.to_torch_dataloader(test_data,test_mask)\n",
    "\n",
    "model_file_name = f'../trained_models/vae_best-input_size:{len(train_data[0])}.pt'\n",
    "\n",
    "total_loss, rmse_loss, kl_loss = test_vae(model_file_name, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start_month, end_month in zip([1,4,7,10], [3,6,9,12]):\n",
    "    start_date = datetime(2018, start_month, 1)\n",
    "    \n",
    "    try:\n",
    "        end_date = datetime(2018, end_month, 31)\n",
    "    except ValueError:\n",
    "        end_date = datetime(2018, end_month, 30)\n",
    "\n",
    "    test_data, test_mask = lending_club_data_handler.get_test_data(test_start, test_end)\n",
    "    test_loader = preprocessing.to_torch(test_data,test_mask)\n",
    "\n",
    "    model_file_name = f'../trained_models/vae_best-input_size:{len(train_data[0])}.pt'\n",
    "\n",
    "    total_loss, rmse_loss, kl_loss = test_vae(model_file_name, test_loader, device)\n",
    "\n",
    "    print(total_loss, rmse_loss, kl_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
